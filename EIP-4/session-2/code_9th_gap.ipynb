{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_9th.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "a813b4d6-a6d9-4a12-e22d-420bde7127fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[13])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31d3102668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqGAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "ba64b201-0332-4bf8-bcf3-cd7cb8fa0049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "0a0a48f5-ea67-4434-8761-f46f6f3f0901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', bias=False, input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', bias=False)) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', bias=False)) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', bias=False))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', bias=False))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', bias=False))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', bias=False))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", use_bias=False)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_158 (Conv2D)          (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_137 (Bat (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_137 (Dropout)        (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_159 (Conv2D)          (None, 24, 24, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_138 (Bat (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_138 (Dropout)        (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_160 (Conv2D)          (None, 24, 24, 10)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 10, 10, 16)        1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_139 (Bat (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_139 (Dropout)        (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 8, 8, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_140 (Bat (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_140 (Dropout)        (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_141 (Bat (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_141 (Dropout)        (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_142 (Bat (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_142 (Dropout)        (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 4, 4, 10)          160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_143 (Bat (None, 4, 4, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_143 (Dropout)        (None, 4, 4, 10)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_8 ( (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,072\n",
            "Trainable params: 13,828\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "b4a1e692-3556-484c-868e-51be9834cc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 14s 235us/step - loss: 0.4039 - acc: 0.9393 - val_loss: 0.0865 - val_acc: 0.9839\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.1088 - acc: 0.9817 - val_loss: 0.0517 - val_acc: 0.9893\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.0775 - acc: 0.9844 - val_loss: 0.0439 - val_acc: 0.9899\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0612 - acc: 0.9863 - val_loss: 0.0362 - val_acc: 0.9904\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0537 - acc: 0.9877 - val_loss: 0.0284 - val_acc: 0.9928\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0474 - acc: 0.9891 - val_loss: 0.0284 - val_acc: 0.9915\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0428 - acc: 0.9901 - val_loss: 0.0294 - val_acc: 0.9914\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0389 - acc: 0.9901 - val_loss: 0.0305 - val_acc: 0.9916\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0364 - acc: 0.9910 - val_loss: 0.0257 - val_acc: 0.9925\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0351 - acc: 0.9915 - val_loss: 0.0237 - val_acc: 0.9921\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0338 - acc: 0.9913 - val_loss: 0.0268 - val_acc: 0.9918\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0329 - acc: 0.9912 - val_loss: 0.0238 - val_acc: 0.9933\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0309 - acc: 0.9917 - val_loss: 0.0203 - val_acc: 0.9936\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0305 - acc: 0.9918 - val_loss: 0.0217 - val_acc: 0.9940\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.0205 - val_acc: 0.9942\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0269 - acc: 0.9930 - val_loss: 0.0197 - val_acc: 0.9936\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0269 - acc: 0.9931 - val_loss: 0.0195 - val_acc: 0.9947\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0252 - acc: 0.9929 - val_loss: 0.0186 - val_acc: 0.9947\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0253 - acc: 0.9931 - val_loss: 0.0179 - val_acc: 0.9941\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0244 - acc: 0.9932 - val_loss: 0.0184 - val_acc: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31c35ec390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "41650f17-5a7c-4b8e-d302-b53817e417f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0184028473936487, 0.9943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}