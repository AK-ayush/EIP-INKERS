{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Week 1 Review:\n",
    "___ \n",
    " [1] Compiled all the individual script files into an intractive jupyter notebook  \n",
    " [2] Done with the singificant and necessary code changes in order to run with latest libraries   \n",
    " [3] Added the necessary code to train the model using `DenseNet` which is SOTA on imagenet Dataset.  \n",
    " ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required libraries\n",
    "!pip install Keras==2.1.6 opencv-python==3.4.1.15 scipy==1.1.0 tensorflow-gpu==1.8.0 Theano==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress the unnecessary warnings  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- If you are using this jupyter notebook behind the proxy network ---\n",
    "# os.environ['http_proxy']=\"http://proxy-server:proxy-port\"\n",
    "# os.environ['https_proxy']=\"http://proxy-server:proxy-port\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the BoxCar116k dataset \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://medusa.fit.vutbr.cz/traffic/data/BoxCars116k.zip\n",
    "!unzip BoxCars116k.zip #update the BOXCARS_DATASET_ROOT from the below cell before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utitlity Funcitons :\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(path, encoding=\"latin-1\", fix_imports=True):\n",
    "    \"\"\"\n",
    "    encoding latin-1 is default for Python2 compatibility\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f, encoding=encoding, fix_imports=True)\n",
    "\n",
    "#%%\n",
    "def save_cache(path, data):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "#%%\n",
    "def ensure_dir(d):\n",
    "    if len(d)  == 0: # for empty dirs (for compatibility with os.path.dirname(\"xxx.yy\"))\n",
    "        return\n",
    "    if not os.path.exists(d):\n",
    "        try:\n",
    "            os.makedirs(d)\n",
    "        except OSError as e:\n",
    "            if e.errno != 17: # FILE EXISTS\n",
    "                raise e\n",
    "                \n",
    "#%%\n",
    "def download_report_hook(block_num, block_size, total_size):\n",
    "    downloaded = block_num*block_size\n",
    "    percents = downloaded / total_size * 100\n",
    "    show_str = \" %.1f%%\"%(percents)\n",
    "    sys.stdout.write(show_str + len(show_str)*\"\\b\")\n",
    "    sys.stdout.flush()\n",
    "    if downloaded >= total_size:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the pre-trained model inorder to reproduce the numerical results of [BoxCars: Improving Vehicle Fine-Grained Recognition using 3D Bounding Boxes in Traffic Surveillance](https://arxiv.org/pdf/1703.00686.pdf)\n",
    "___\n",
    "Net | Original 3DBBs | Estimated 3DBBs | Image Processing Time\n",
    "----|---------------:|---------------:|---------------------:\n",
    "ResNet50 |  84.29/91.61 | 81.78/90.79  | 5.8ms\n",
    "VGG16 | 84.10/92.09 | 81.43/90.68 | 5.4ms\n",
    "VGG19 | 83.35/91.23 | 81.93/91.48  | 5.4ms\n",
    "InceptionV3 | 81.51/89.86 | 79.89/89.92 | 6.1ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to by filled by the user\n",
    "#%%\n",
    "MODELS_DIR_URL = \"https://medusa.fit.vutbr.cz/traffic/data/BoxCars-models/\"\n",
    "SUFFIX = \"h5\"\n",
    "\n",
    "#output directory where to put downloaded models\n",
    "DEFAULT_OUTPUT_DIR = os.path.realpath(os.path.join(\".\", \"models\")) \n",
    "\n",
    "all_nets = True\n",
    "net_name = None #download all available models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download trained model files. Available nets: ['InceptionV3', 'InceptionV3_estimated3DBB', 'ResNet50', 'ResNet50_estimated3DBB', 'VGG16', 'VGG16_estimated3DBB', 'VGG19', 'VGG19_estimated3DBB']\n",
      "Saving downloaded models to: /project/BoxCars_new/scripts/models\n",
      "Downloading InceptionV3... Downloading InceptionV3_estimated3DBB... Downloading ResNet50... Downloading ResNet50_estimated3DBB... Downloading VGG16... Downloading VGG16_estimated3DBB... Downloading VGG19... Downloading VGG19_estimated3DBB... "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib.request \n",
    "import re\n",
    "\n",
    "# --- If you are using this jupyter notebook behind the proxy network\n",
    "# handler=urllib.request.ProxyHandler({'http':'http://proxy-server:proxy-port',\n",
    "#                                      'https':'http://proxy-server:proxy-port'})\n",
    "# opener=urllib.request.build_opener(handler)\n",
    "# urllib.request.install_opener(opener)\n",
    "\n",
    "#%%\n",
    "with urllib.request.urlopen(MODELS_DIR_URL) as response:\n",
    "    dir_listing = response.read().decode(\"utf-8\")\n",
    "\n",
    "model_matcher = re.compile(r'href=\"(.*)\\.%s\"'%(SUFFIX))\n",
    "available_nets = model_matcher.findall(dir_listing)\n",
    "\n",
    "print(\"Download trained model files. Available nets: %s\"%(str(available_nets)))\n",
    "\n",
    "download_nets = net_name\n",
    "if all_nets:\n",
    "    download_nets = available_nets\n",
    "    \n",
    "if len(download_nets) == 0:\n",
    "    print(\"You need to specify net_name to download or use all_nets=True to download all of them\\nAVAILABLE NETS: %s\\n\"%(str(available_nets)))\n",
    "    sys.exit(1)\n",
    "\n",
    "#%%\n",
    "print(\"Saving downloaded models to: %s\"%(DEFAULT_OUTPUT_DIR))\n",
    "ensure_dir(DEFAULT_OUTPUT_DIR)\n",
    "for net in download_nets:\n",
    "    if net not in available_nets:\n",
    "        print(\"WARNING: Skipping %s because it is not available. AVAILABLE_NETS: %s\"%(net, str(available_nets)))\n",
    "        continue\n",
    "    print(\"Downloading %s... \\n\"%(net), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "    urllib.request.urlretrieve(MODELS_DIR_URL + net + \".\" + SUFFIX, os.path.join(args.output_dir, \"%s.%s\"%(net, SUFFIX)), download_report_hook)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the necessary directories:\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# change this to your location\n",
    "# BOXCARS_DATASET_ROOT = \"/mnt/matylda1/isochor/Datasets/BoxCars116k/\" \n",
    "BOXCARS_DATASET_ROOT = \"BoxCars116k/\"\n",
    "#%%\n",
    "BOXCARS_IMAGES_ROOT = os.path.join(BOXCARS_DATASET_ROOT, \"images\")\n",
    "BOXCARS_DATASET = os.path.join(BOXCARS_DATASET_ROOT, \"dataset.pkl\")\n",
    "BOXCARS_ATLAS = os.path.join(BOXCARS_DATASET_ROOT, \"atlas.pkl\")\n",
    "BOXCARS_CLASSIFICATION_SPLITS = os.path.join(BOXCARS_DATASET_ROOT, \"classification_splits.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoxDataset Class Object :\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class BoxCarsDataset(object):\n",
    "    def __init__(self, load_atlas = False, load_split = None, use_estimated_3DBB = False, estimated_3DBB_path = None):\n",
    "        self.dataset = load_cache(BOXCARS_DATASET)\n",
    "        self.use_estimated_3DBB = use_estimated_3DBB\n",
    "        \n",
    "        self.atlas = None\n",
    "        self.split = None\n",
    "        self.split_name = None\n",
    "        self.estimated_3DBB = None\n",
    "        self.X = {}\n",
    "        self.Y = {}\n",
    "        for part in (\"train\", \"validation\", \"test\"):\n",
    "            self.X[part] = None\n",
    "            self.Y[part] = None # for labels as array of 0-1 flags\n",
    "            \n",
    "        if load_atlas:\n",
    "            self.load_atlas()\n",
    "        if load_split is not None:\n",
    "            self.load_classification_split(load_split)\n",
    "        if self.use_estimated_3DBB:\n",
    "            self.estimated_3DBB = load_cache(estimated_3DBB_path)\n",
    "        \n",
    "    #%%\n",
    "    def load_atlas(self):\n",
    "        self.atlas = load_cache(BOXCARS_ATLAS)\n",
    "    \n",
    "    #%%\n",
    "    def load_classification_split(self, split_name):\n",
    "        self.split = load_cache(BOXCARS_CLASSIFICATION_SPLITS)[split_name]\n",
    "        self.split_name = split_name\n",
    "       \n",
    "    #%%\n",
    "    def get_image(self, vehicle_id, instance_id):\n",
    "        \"\"\"\n",
    "        returns decoded image from atlas in RGB channel order\n",
    "        \"\"\"\n",
    "        return cv2.cvtColor(cv2.imdecode(self.atlas[vehicle_id][instance_id], 1), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    #%%\n",
    "    def get_vehicle_instance_data(self, vehicle_id, instance_id, original_image_coordinates=False):\n",
    "        \"\"\"\n",
    "        original_image_coordinates: the 3DBB coordinates are in the original image space\n",
    "                                    to convert them into cropped image space, it is necessary to subtract instance[\"3DBB_offset\"]\n",
    "                                    which is done if this parameter is False. \n",
    "        \"\"\"\n",
    "        vehicle = self.dataset[\"samples\"][vehicle_id]\n",
    "        instance = vehicle[\"instances\"][instance_id]\n",
    "        if not self.use_estimated_3DBB:\n",
    "            bb3d = self.dataset[\"samples\"][vehicle_id][\"instances\"][instance_id][\"3DBB\"]\n",
    "        else:\n",
    "            bb3d = self.estimated_3DBB[vehicle_id][instance_id]\n",
    "            \n",
    "        if not original_image_coordinates:\n",
    "            bb3d = bb3d - instance[\"3DBB_offset\"]\n",
    "\n",
    "        return vehicle, instance, bb3d \n",
    "            \n",
    "       \n",
    "    #%%\n",
    "    def initialize_data(self, part):\n",
    "        assert self.split is not None, \"load classification split first\"\n",
    "        assert part in self.X, \"unknown part -- use: train, validation, test\"\n",
    "        assert self.X[part] is None, \"part %s was already initialized\"%part\n",
    "        data = self.split[part]\n",
    "        x, y = [], []\n",
    "        for vehicle_id, label in data:\n",
    "            num_instances = len(self.dataset[\"samples\"][vehicle_id][\"instances\"])\n",
    "            x.extend([(vehicle_id, instance_id) for instance_id in range(num_instances)])\n",
    "            y.extend([label]*num_instances)\n",
    "        self.X[part] = np.asarray(x,dtype=int)\n",
    "\n",
    "        y = np.asarray(y,dtype=int)\n",
    "        y_categorical = np.zeros((y.shape[0], self.get_number_of_classes()))\n",
    "        y_categorical[np.arange(y.shape[0]), y] = 1\n",
    "        self.Y[part] = y_categorical\n",
    "        print (\"initialize_data\\n\", self.X[part].shape, self.Y[part].shape)\n",
    "        \n",
    "\n",
    "\n",
    "    def get_number_of_classes(self):\n",
    "        return len(self.split[\"types_mapping\"])\n",
    "        \n",
    "        \n",
    "    def evaluate(self, probabilities, part=\"test\", top_k=1):\n",
    "        samples = self.X[part]\n",
    "        print (samples.shape, probabilities.shape)\n",
    "        assert samples.shape[0] == probabilities.shape[0]\n",
    "        assert self.get_number_of_classes() == probabilities.shape[1]\n",
    "        part_data = self.split[part]\n",
    "        probs_inds = {}\n",
    "        for vehicle_id, _ in part_data:\n",
    "            probs_inds[vehicle_id] = np.zeros(len(self.dataset[\"samples\"][vehicle_id][\"instances\"]), dtype=int)\n",
    "        for i, (vehicle_id, instance_id) in enumerate(samples):\n",
    "            probs_inds[vehicle_id][instance_id] = i\n",
    "            \n",
    "        get_hit = lambda probs, gt: int(gt in np.argsort(probs.flatten())[-top_k:])\n",
    "        hits = []\n",
    "        hits_tracks = []\n",
    "        for vehicle_id, label in part_data:\n",
    "            inds = probs_inds[vehicle_id]\n",
    "            hits_tracks.append(get_hit(np.mean(probabilities[inds, :], axis=0), label))\n",
    "            for ind in inds:\n",
    "                hits.append(get_hit(probabilities[ind, :], label))\n",
    "                \n",
    "        return np.mean(hits), np.mean(hits_tracks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxcars Image Transformations Auxilary Methods :\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#%%\n",
    "def alter_HSV(img, change_probability = 0.6):\n",
    "    if random.random() < 1-change_probability:\n",
    "        return img\n",
    "    addToHue = random.randint(0,179)\n",
    "    addToSaturation = random.gauss(60, 20)\n",
    "    addToValue = random.randint(-50,50)\n",
    "    hsvVersion =  cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    channels = hsvVersion.transpose(2, 0, 1)\n",
    "    channels[0] = ((channels[0].astype(int) + addToHue)%180).astype(np.uint8)\n",
    "    channels[1] = (np.maximum(0, np.minimum(255, (channels[1].astype(int) + addToSaturation)))).astype(np.uint8)\n",
    "    channels[2] = (np.maximum(0, np.minimum(255, (channels[2].astype(int) + addToValue)))).astype(np.uint8)\n",
    "    hsvVersion = channels.transpose(1,2,0)   \n",
    "        \n",
    "    return cv2.cvtColor(hsvVersion, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "#%%\n",
    "def image_drop(img, change_probability = 0.6):\n",
    "    if random.random() < 1-change_probability:\n",
    "        return img\n",
    "    width = random.randint(int(img.shape[1]*0.10), int(img.shape[1]*0.3))\n",
    "    height = random.randint(int(img.shape[0]*0.10), int(img.shape[0]*0.3))\n",
    "    x = random.randint(int(img.shape[1]*0.10), img.shape[1]-width-int(img.shape[1]*0.10))\n",
    "    y = random.randint(int(img.shape[0]*0.10), img.shape[0]-height-int(img.shape[0]*0.10))\n",
    "    img[y:y+height,x:x+width,:] = (np.random.rand(height,width,3)*255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "#%%\n",
    "def add_bb_noise_flip(image, bb3d, flip, bb_noise):\n",
    "    bb3d = bb3d + bb_noise \n",
    "    if flip:\n",
    "        bb3d[:, 0] = image.shape[1] - bb3d[:,0]\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image, bb3d\n",
    "\n",
    "#%%\n",
    "def _unpack_side(img, origPoints, targetSize):\n",
    "    origPoints = np.array(origPoints).reshape(-1,1,2)\n",
    "    targetPoints = np.array([(0,0), (targetSize[0],0), (0, targetSize[1]), \n",
    "                             (targetSize[0], targetSize[1])]).reshape(-1,1,2).astype(origPoints.dtype)\n",
    "    m, _ = cv2.findHomography(origPoints, targetPoints, 0)\n",
    "    resultImage = cv2.warpPerspective(img, m, targetSize)\n",
    "    return resultImage\n",
    "    \n",
    "    \n",
    "#%%    \n",
    "def unpack_3DBB(img, bb):\n",
    "    frontal = _unpack_side(img, [bb[0], bb[1], bb[4], bb[5]], (75,124))\n",
    "    side = _unpack_side(img, [bb[1], bb[2], bb[5], bb[6]], (149,124))\n",
    "    roof = _unpack_side(img, [bb[0], bb[3], bb[1], bb[2]], (149,100))\n",
    "    \n",
    "    final = np.zeros((224,224,3), dtype=frontal.dtype)\n",
    "    final[100:, 0:75] = frontal\n",
    "    final[0:100, 75:] = roof\n",
    "    final[100:, 75:] = side\n",
    "    \n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoxDataGenerator Object to populate the data in batches : \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "\n",
    "#%%\n",
    "class BoxCarsDataGenerator(Iterator):\n",
    "    def __init__(self, dataset, part, batch_size=8, training_mode=False, seed=None, generate_y = True, image_size = (224,224)):\n",
    "        assert image_size == (224,224), \"only images 224x224 are supported by unpack_3DBB for now, if necessary it can be changed\"\n",
    "        assert dataset.X[part] is not None, \"load some classification split first\"\n",
    "        super().__init__(dataset.X[part].shape[0], batch_size, training_mode, seed)\n",
    "        self.part = part\n",
    "        self.generate_y = generate_y\n",
    "        self.dataset = dataset\n",
    "        self.image_size = image_size\n",
    "        self.training_mode = training_mode\n",
    "        if self.dataset.atlas is None:\n",
    "            self.dataset.load_atlas()\n",
    "            \n",
    "    #%%\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        current_batch_size = len(index_array)\n",
    "        x = np.empty([current_batch_size] + list(self.image_size) + [3], dtype=np.float32)\n",
    "        for i, ind in enumerate(index_array):\n",
    "            vehicle_id, instance_id = self.dataset.X[self.part][ind]\n",
    "            vehicle, instance, bb3d = self.dataset.get_vehicle_instance_data(vehicle_id, instance_id)\n",
    "            image = self.dataset.get_image(vehicle_id, instance_id)\n",
    "            if self.training_mode:\n",
    "                image = alter_HSV(image) # randomly alternate color\n",
    "                image = image_drop(image) # randomly remove part of the image\n",
    "                bb_noise = np.clip(np.random.randn(2) * 1.5, -5, 5) # generate random bounding box movement\n",
    "                flip = bool(random.getrandbits(1)) # random flip\n",
    "                image, bb3d = add_bb_noise_flip(image, bb3d, flip, bb_noise) \n",
    "            image = unpack_3DBB(image, bb3d) \n",
    "            image = (image.astype(np.float32) - 116)/128.\n",
    "            x[i, ...] = image\n",
    "        if not self.generate_y:\n",
    "            return x\n",
    "        y = self.dataset.Y[self.part][index_array]\n",
    "        print (x.shape, y.shape)\n",
    "        return x, y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainging Related Auxilary Functions:\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.densenet import DenseNet169,DenseNet121,DenseNet201\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Flatten, Dropout, AveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Related External Arguments:\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_3DBB_path = None  #use estimated 3DBBs from specified path\n",
    "evaluation_path = 'models/ResNet50.h5' #path to model file to be evaluated\n",
    "resume_path = None  #path to model file to be resumed\n",
    "\n",
    "output_final_model_path = None  \n",
    "tensorboard_dir = None\n",
    "snapshots_dir = None\n",
    "\n",
    "training_network = \"ResNet50\" # train on one of following available nets: [\"ResNet50\", \"VGG16\", \"VGG19\", \"InceptionV3\", \"DenseNet121\", \"DenseNet169\", \"DenseNet201\"]\n",
    "cache_path = \"../cache/\"  #where to store training meta-data and final model\n",
    "'''------------------------------------------------------------'''\n",
    "lr = 0.0025 #learning rate\n",
    "batch_size = 16\n",
    "epochs = 10 #run for epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% initialize dataset object\n",
    "if estimated_3DBB_path is None:\n",
    "    dataset = BoxCarsDataset(load_split=\"hard\", load_atlas=True)\n",
    "else:\n",
    "    dataset = BoxCarsDataset(load_split=\"hard\", load_atlas=True, \n",
    "                             use_estimated_3DBB = True, estimated_3DBB_path = estimated_3DBB_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/ResNet50.h5\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "#%% get optional path to load model\n",
    "model = None\n",
    "for path in [evaluation_path, resume_path]:\n",
    "    if path is not None:\n",
    "        print(\"Loading model from %s\"%path)\n",
    "        model = load_model(path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is None:\n",
    "    print(\"Initializing new %s model ...\"%training_network)\n",
    "    if training_network in (\"ResNet50\", ):\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        x = Flatten()(base_model.output)\n",
    "    \n",
    "    if training_network in (\"DenseNet121\", \"DenseNet169\", \"DenseNet201\"):\n",
    "        if training_network == \"DenseNet121\":\n",
    "            base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        elif training_network == \"DenseNet169\":\n",
    "            base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        elif training_network == \"DenseNet201\":\n",
    "            base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        x = Flatten()(base_model.output)\n",
    "        \n",
    "    if training_network in (\"VGG16\", \"VGG19\"):\n",
    "        if training_network == \"VGG16\":\n",
    "            base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        elif training_network == \"VGG19\":\n",
    "            base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        x = Flatten()(base_model.output)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    if training_network in (\"InceptionV3\", ):\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "        output_dim = int(base_model.outputs[0].get_shape()[1])\n",
    "        x = AveragePooling2D((output_dim, output_dim), strides=(output_dim, output_dim), name='avg_pool')(base_model.output)\n",
    "        x = Flatten()(x)\n",
    "    \n",
    "            \n",
    "    predictions = Dense(dataset.get_number_of_classes(), activation='softmax')(x)\n",
    "    model = Model(input=base_model.input, output=predictions, name=\"%s%s\"%(training_network, {True: \"_estimated3DBB\", False:\"\"}[estimated_3DBB_path is not None]))\n",
    "    optimizer = SGD(lr=lr, decay=1e-4, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: ResNet50\n"
     ]
    }
   ],
   "source": [
    "print(\"Model name: %s\"%(model.name))\n",
    "if estimated_3DBB_path is not None and \"estimated3DBB\" not in model.name:\n",
    "    print(\"ERROR: using estimated 3DBBs with model trained on original 3DBBs\")\n",
    "    sys.exit(1)\n",
    "if estimated_3DBB_path is None and \"estimated3DBB\" in model.name:\n",
    "    print(\"ERROR: using model trained on estimated 3DBBs and running on original 3DBBs\")\n",
    "    sys.exit(1)\n",
    "\n",
    "output_final_model_path = os.path.join(cache_path, model.name, \"final_model.h5\")\n",
    "snapshots_dir = os.path.join(cache_path, model.name, \"snapshots\")\n",
    "tensorboard_dir = os.path.join(cache_path, model.name, \"tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% training\n",
    "if evaluation_path is None:\n",
    "    print(\"Training...\")\n",
    "    #%% initialize dataset for training\n",
    "    dataset.initialize_data(\"train\")\n",
    "    dataset.initialize_data(\"validation\")\n",
    "    generator_train = BoxCarsDataGenerator(dataset, \"train\", batch_size, training_mode=True)\n",
    "    generator_val = BoxCarsDataGenerator(dataset, \"validation\", batch_size, training_mode=False)\n",
    "\n",
    "\n",
    "    #%% callbacks\n",
    "    ensure_dir(tensorboard_dir)\n",
    "    ensure_dir(snapshots_dir)\n",
    "    tb_callback = TensorBoard(tensorboard_dir, histogram_freq=1, write_graph=False, write_images=False)\n",
    "    saver_callback = ModelCheckpoint(os.path.join(snapshots_dir, \"model_{epoch:03d}_{val_acc:.2f}.h5\"), period=4 )\n",
    "\n",
    "    #%% get initial epoch\n",
    "    initial_epoch = 0\n",
    "    if resume_path is not None:\n",
    "        initial_epoch = int(os.path.basename(resume_path).split(\"_\")[1]) + 1\n",
    "\n",
    "\n",
    "    model.fit_generator(generator=generator_train, \n",
    "                        steps_per_epoch=generator_train.n,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=generator_val,\n",
    "                        validation_steps=generator_val.n,\n",
    "                        callbacks=[tb_callback, saver_callback],\n",
    "                        initial_epoch = initial_epoch,\n",
    "                        )\n",
    "\n",
    "    #%% save trained data\n",
    "    print(\"Saving the final model to %s\"%(output_final_model_path))\n",
    "    ensure_dir(os.path.dirname(output_final_model_path))\n",
    "    model.save(output_final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is evaluated when the training is finished or can be evaluated on saved weights\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n",
      "initialize_data\n",
      " (39149, 2) (39149, 107)\n",
      "10589/39149 [=======>......................] - ETA: 26:12"
     ]
    }
   ],
   "source": [
    "#%% evaluate the model \n",
    "print(\"Running evaluation...\")\n",
    "dataset.initialize_data(\"test\")\n",
    "generator_test = BoxCarsDataGenerator(dataset, \"test\", batch_size, training_mode=False, generate_y=False)\n",
    "start_time = time.time()\n",
    "predictions = model.predict_generator(generator_test, generator_test.n, verbose=1)\n",
    "end_time = time.time()\n",
    "single_acc, tracks_acc = dataset.evaluate(predictions)\n",
    "print(\" -- Accuracy: %.2f%%\"%(single_acc*100))\n",
    "print(\" -- Track accuracy: %.2f%%\"%(tracks_acc*100))\n",
    "print(\" -- Image processing time: %.1fms\"%((end_time-start_time)/generator_test.n*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
